{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.degrees(math.atan2(t0, t1))\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.degrees(math.asin(t2))\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.degrees(math.atan2(t3, t4))\n",
    "\n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train.csv.zip', 'X_test.csv.zip', 'y_train.csv', 'X_test.csv', 'train_transform', 'Untitled.ipynb', 'sample_submission.csv', 'test_transform', '.ipynb_checkpoints', 'X_train.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainX = pd.read_csv('X_train.csv')\n",
    "trainY = pd.read_csv('y_train.csv')\n",
    "#testX = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_new=pd.read_csv('train_transform',sep='\\t')\n",
    "testX_new=pd.read_csv('test_transform',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487680, 14)\n",
      "measurement_number          0\n",
      "orientation_X         162.908\n",
      "orientation_Y        -1.41335\n",
      "orientation_Z          80.023\n",
      "Name: 0, dtype: object\n",
      "Unnamed: 0                        0\n",
      "row_id                          0_0\n",
      "series_id                         0\n",
      "measurement_number                0\n",
      "orientation_X               162.908\n",
      "orientation_Y              -1.41335\n",
      "orientation_Z                80.023\n",
      "angular_velocity_X          0.10765\n",
      "angular_velocity_Y         0.017561\n",
      "angular_velocity_Z       0.00076741\n",
      "linear_acceleration_X      -0.74857\n",
      "linear_acceleration_Y         2.103\n",
      "linear_acceleration_Z       -9.7532\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(trainX_new.shape)\n",
    "print(trainX_new.iloc[0,3:7])\n",
    "trainX_new.drop(columns='orientation_W',axis=1, inplace=True)\n",
    "print(trainX_new.iloc[0,])\n",
    "testX_new.drop(columns='orientation_W',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 500,\n",
    "         'min_data_in_leaf': 10, \n",
    "         'objective':'multiclass',\n",
    "         'num_class': 9,\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'multi_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "max_iter = 5\n",
    "target = trainY.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "0    0\n",
      "dtype: int64\n",
      "0    8\n",
      "dtype: int64\n",
      "(3810, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(target))\n",
    "#target=targeto\n",
    "targetc=pd.DataFrame(pd.factorize(target)[0] )\n",
    "print(type(targetc))\n",
    "print(targetc.min())\n",
    "print(targetc.max())\n",
    "target=targetc\n",
    "#target = pd.DataFrame(label_binarize(targetc, classes=[1,2,3,4,5,6,7,8,9]))\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 row_id  series_id  measurement_number  orientation_X  \\\n",
      "0           0    0_0          0                   0     162.907503   \n",
      "1           1    0_1          0                   1     162.903307   \n",
      "2           2    0_2          0                   2     162.904723   \n",
      "3           3    0_3          0                   3     162.902555   \n",
      "4           4    0_4          0                   4     162.903073   \n",
      "\n",
      "   orientation_Y  orientation_Z  angular_velocity_X  angular_velocity_Y  \\\n",
      "0      -1.413350      80.022953            0.107650            0.017561   \n",
      "1      -1.413029      80.021948            0.067851            0.029939   \n",
      "2      -1.416828      80.023985            0.007275            0.028934   \n",
      "3      -1.419195      80.026215           -0.013053            0.019448   \n",
      "4      -1.420043      80.024612            0.005135            0.007652   \n",
      "\n",
      "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
      "0            0.000767               -0.74857                 2.1030   \n",
      "1            0.003386                0.33995                 1.5064   \n",
      "2           -0.005978               -0.26429                 1.5922   \n",
      "3           -0.008974                0.42684                 1.0993   \n",
      "4            0.005245               -0.50969                 1.4689   \n",
      "\n",
      "   linear_acceleration_Z  \n",
      "0                -9.7532  \n",
      "1                -9.4128  \n",
      "2                -8.7267  \n",
      "3               -10.0960  \n",
      "4               -10.4410  \n"
     ]
    }
   ],
   "source": [
    "print(trainX_new.iloc[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orientation_X               162.908\n",
      "orientation_Y              -1.41335\n",
      "orientation_Z                80.023\n",
      "angular_velocity_X          0.10765\n",
      "angular_velocity_Y         0.017561\n",
      "angular_velocity_Z       0.00076741\n",
      "linear_acceleration_X      -0.74857\n",
      "linear_acceleration_Y         2.103\n",
      "linear_acceleration_Z       -9.7532\n",
      "Name: 0, dtype: object\n",
      "3810\n",
      "<class 'pandas.core.series.Series'>\n",
      "(0, 1152)\n",
      "(3810, 1152)\n"
     ]
    }
   ],
   "source": [
    "print(trainX_new.iloc[0,4:13])\n",
    "print(len(target))\n",
    "#for i in range(0,len(target)):\n",
    "print(type(trainX_new.iloc[0,4:13]))\n",
    "col_names =  range(0,128*9)\n",
    "trainX_new1  = pd.DataFrame(columns = col_names)\n",
    "print(trainX_new1.shape)\n",
    "for i in range(0,len(target)):\n",
    "    c=[]\n",
    "    for j in range(0,128):\n",
    "        c=c+list(trainX_new.iloc[i*128+j,4:13])\n",
    "    trainX_new1.loc[i]=c\n",
    "print(trainX_new1.shape)    \n",
    "#print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1152)\n",
      "(3816, 1152)\n"
     ]
    }
   ],
   "source": [
    "col_names =  range(0,128*9)\n",
    "testX_new1  = pd.DataFrame(columns = col_names)\n",
    "print(testX_new1.shape)\n",
    "for i in range(0,int(testX_new.shape[0]/128)):\n",
    "    c=[]\n",
    "    for j in range(0,128):\n",
    "        c=c+list(testX_new.iloc[i*128+j,4:13])\n",
    "    testX_new1.loc[i]=c\n",
    "print(testX_new1.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       float64\n",
       "1       float64\n",
       "2       float64\n",
       "3       float64\n",
       "4       float64\n",
       "5       float64\n",
       "6       float64\n",
       "7       float64\n",
       "8       float64\n",
       "9       float64\n",
       "10      float64\n",
       "11      float64\n",
       "12      float64\n",
       "13      float64\n",
       "14      float64\n",
       "15      float64\n",
       "16      float64\n",
       "17      float64\n",
       "18      float64\n",
       "19      float64\n",
       "20      float64\n",
       "21      float64\n",
       "22      float64\n",
       "23      float64\n",
       "24      float64\n",
       "25      float64\n",
       "26      float64\n",
       "27      float64\n",
       "28      float64\n",
       "29      float64\n",
       "         ...   \n",
       "1122    float64\n",
       "1123    float64\n",
       "1124    float64\n",
       "1125    float64\n",
       "1126    float64\n",
       "1127    float64\n",
       "1128    float64\n",
       "1129    float64\n",
       "1130    float64\n",
       "1131    float64\n",
       "1132    float64\n",
       "1133    float64\n",
       "1134    float64\n",
       "1135    float64\n",
       "1136    float64\n",
       "1137    float64\n",
       "1138    float64\n",
       "1139    float64\n",
       "1140    float64\n",
       "1141    float64\n",
       "1142    float64\n",
       "1143    float64\n",
       "1144    float64\n",
       "1145    float64\n",
       "1146    float64\n",
       "1147    float64\n",
       "1148    float64\n",
       "1149    float64\n",
       "1150    float64\n",
       "1151    float64\n",
       "Length: 1152, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_new1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.16937\tvalid_1's multi_logloss: 1.38508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 1.16937\tvalid_1's multi_logloss: 1.38508\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.016s\n",
      "fold n°1\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17989\tvalid_1's multi_logloss: 1.44398\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 1.17989\tvalid_1's multi_logloss: 1.44398\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.032s\n",
      "fold n°2\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17915\tvalid_1's multi_logloss: 1.43554\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 1.17915\tvalid_1's multi_logloss: 1.43554\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.047s\n",
      "fold n°3\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.15291\tvalid_1's multi_logloss: 1.4516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 1.15291\tvalid_1's multi_logloss: 1.4516\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.063s\n",
      "fold n°4\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.17215\tvalid_1's multi_logloss: 1.41019\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_logloss: 1.17215\tvalid_1's multi_logloss: 1.41019\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.078s\n",
      "CV score: 0.05643 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros((len(target),9))\n",
    "#categorical_columns = [c for c in categorical_columns if c not in ['MachineIdentifier']]\n",
    "#print(trainX_new1.iloc[1,])\n",
    "features = trainX_new1.columns\n",
    "predictions = np.zeros((len(testX_new1),9))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "start_time= time.time()\n",
    "score = [0 for _ in range(folds.n_splits)]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(trainX_new1.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print(len(trn_idx))\n",
    "    print(len(val_idx))\n",
    "    print(len(features))\n",
    "    trn_data = lgb.Dataset(trainX_new1.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           #categorical_feature = categorical_columns\n",
    "                          )\n",
    "    val_data = lgb.Dataset(trainX_new1.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           #categorical_feature = categorical_columns\n",
    "                          )\n",
    "\n",
    "    #print(trn_data.shape)\n",
    "    #print(val_data.shape)\n",
    "    num_round = 100\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "    print(trainX_new1.iloc[val_idx][features].shape)\n",
    "    print(trainX_new1.iloc[trn_idx][features].shape)\n",
    "    #tmp = clf.predict(trainX_new1.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    #print(tmp.shape)\n",
    "    oof[val_idx] = clf.predict(trainX_new1.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # we perform predictions by chunks\n",
    "    initial_idx = 0\n",
    "    chunk_size = 1000000\n",
    "    current_pred = np.zeros((len(testX_new1),9))\n",
    "    while initial_idx < testX_new1.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, testX_new1.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = clf.predict(testX_new1.iloc[idx][features], num_iteration=clf.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "    predictions += current_pred / min(folds.n_splits, max_iter)\n",
    "   \n",
    "    print(\"time elapsed: {:<5.2}s\".format((time.time() - start_time) / 3600))\n",
    "    #score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    tmp1=np.argmax(target.iloc[val_idx],axis=1)\n",
    "    tmp2=np.argmax(oof[val_idx],axis=1)\n",
    "    score[fold_] = metrics.accuracy_score(tmp1,tmp2)\n",
    "    if fold_ == max_iter - 1: break\n",
    "        \n",
    "if (folds.n_splits == max_iter):\n",
    "    #print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\n",
    "    tmp1=np.argmax(target,axis=1)\n",
    "    tmp2=np.argmax(oof,axis=1)\n",
    "    print(\"CV score: {:<8.5f}\".format(metrics.accuracy_score(tmp1,tmp2)))\n",
    "else:\n",
    "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06955380577427822, 0.045931758530183726, 0.049868766404199474, 0.048556430446194225, 0.06824146981627296]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09083681 0.18395413 0.05818642 0.20215155 0.1406639  0.07764523\n",
      " 0.11181966 0.00372593 0.13101638]\n",
      "3\n",
      "tiled\n",
      "tiled\n"
     ]
    }
   ],
   "source": [
    "targetx = trainY.iloc[:,2]\n",
    "cate=targetx.unique()\n",
    "predictions_new=np.argmax(predictions,axis=1)\n",
    "print(predictions[0,])\n",
    "print(predictions_new[0])\n",
    "print(cate[predictions_new[0]])\n",
    "predictions_new1=cate[predictions_new]\n",
    "print(predictions_new1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"series_id\": list(range(3816))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816\n",
      "(3816, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>soft_pvc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id     surface\n",
       "0          0       tiled\n",
       "1          1    concrete\n",
       "2          2       tiled\n",
       "3          3      carpet\n",
       "4          4  soft_tiles\n",
       "5          5    concrete\n",
       "6          6    concrete\n",
       "7          7    concrete\n",
       "8          8    soft_pvc\n",
       "9          9        wood"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions_new1))\n",
    "print(sub_df.shape)\n",
    "sub_df[\"surface\"] = predictions_new1\n",
    "sub_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('lgb_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

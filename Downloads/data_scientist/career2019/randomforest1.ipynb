{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Libraries Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.degrees(math.atan2(t0, t1))\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.degrees(math.asin(t2))\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.degrees(math.atan2(t3, t4))\n",
    "\n",
    "    return X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train.csv.zip', 'X_test.csv.zip', 'y_train.csv', 'X_test.csv', 'train_transform', 'Untitled.ipynb', 'sample_submission.csv', 'lgb_submit.csv', 'test_transform', 'lightgbm.ipynb', '.ipynb_checkpoints', 'X_train.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.read_csv('X_train.csv')\n",
    "trainY = pd.read_csv('y_train.csv')\n",
    "testX = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_new=pd.read_csv('train_transform',sep='\\t')\n",
    "testX_new=pd.read_csv('test_transform',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487680, 14)\n",
      "measurement_number          0\n",
      "orientation_X         162.908\n",
      "orientation_Y        -1.41335\n",
      "orientation_Z          80.023\n",
      "Name: 0, dtype: object\n",
      "Unnamed: 0                        0\n",
      "row_id                          0_0\n",
      "series_id                         0\n",
      "measurement_number                0\n",
      "orientation_X               162.908\n",
      "orientation_Y              -1.41335\n",
      "orientation_Z                80.023\n",
      "angular_velocity_X          0.10765\n",
      "angular_velocity_Y         0.017561\n",
      "angular_velocity_Z       0.00076741\n",
      "linear_acceleration_X      -0.74857\n",
      "linear_acceleration_Y         2.103\n",
      "linear_acceleration_Z       -9.7532\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(trainX_new.shape)\n",
    "print(trainX_new.iloc[0,3:7])\n",
    "trainX_new.drop(columns='orientation_W',axis=1, inplace=True)\n",
    "print(trainX_new.iloc[0,])\n",
    "testX_new.drop(columns='orientation_W',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_new['new1']=trainX.iloc[:,3]\n",
    "trainX_new['new2']=trainX.iloc[:,4]\n",
    "trainX_new['new3']=trainX.iloc[:,5]\n",
    "trainX_new['new4']=trainX.iloc[:,6]\n",
    "testX_new['new1']=testX.iloc[:,3]\n",
    "testX_new['new2']=testX.iloc[:,4]\n",
    "testX_new['new3']=testX.iloc[:,5]\n",
    "testX_new['new4']=testX.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                       0\n",
      "row_id                         0_0\n",
      "series_id                        0\n",
      "measurement_number               0\n",
      "orientation_X              162.991\n",
      "orientation_Y            -0.816677\n",
      "orientation_Z              177.135\n",
      "angular_velocity_X      -0.0065237\n",
      "angular_velocity_Y      -0.0010714\n",
      "angular_velocity_Z        -0.02739\n",
      "linear_acceleration_X      0.10043\n",
      "linear_acceleration_Y       4.2061\n",
      "linear_acceleration_Z      -5.5439\n",
      "new1                     -0.025773\n",
      "new2                      -0.98864\n",
      "new3                      -0.14801\n",
      "new4                       0.00335\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(testX_new.iloc[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 10,\n",
    "         'min_data_in_leaf': 10, \n",
    "         'objective':'multiclass',\n",
    "         'num_class': 9,\n",
    "         'max_depth': 2,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'multi_error',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "max_iter = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "0\n",
      "8\n",
      "(3810,)\n"
     ]
    }
   ],
   "source": [
    "target = trainY.iloc[:,2]\n",
    "print(type(target))\n",
    "#target=targeto\n",
    "targetc=pd.factorize(target)[0]\n",
    "print(type(targetc))\n",
    "print(targetc.min())\n",
    "print(targetc.max())\n",
    "target=targetc\n",
    "#target = pd.DataFrame(label_binarize(targetc, classes=[1,2,3,4,5,6,7,8,9]))\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487680, 17)\n",
      "3810\n",
      "<class 'pandas.core.series.Series'>\n",
      "(0, 1664)\n",
      "(3810, 1664)\n"
     ]
    }
   ],
   "source": [
    "print(trainX_new.shape)\n",
    "print(len(target))\n",
    "#for i in range(0,len(target)):\n",
    "print(type(trainX_new.iloc[0,4:17]))\n",
    "col_names =  range(0,128*13)\n",
    "trainX_new1  = pd.DataFrame(columns = col_names)\n",
    "print(trainX_new1.shape)\n",
    "for i in range(0,len(target)):\n",
    "    c=[]\n",
    "    for j in range(0,128):\n",
    "        c=c+list(trainX_new.iloc[i*128+j,4:17])\n",
    "    trainX_new1.loc[i]=c\n",
    "print(trainX_new1.shape)    \n",
    "#print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488448, 17)\n",
      "(0, 1664)\n",
      "(3816, 1664)\n"
     ]
    }
   ],
   "source": [
    "print(testX_new.shape)\n",
    "col_names =  range(0,128*13)\n",
    "testX_new1  = pd.DataFrame(columns = col_names)\n",
    "print(testX_new1.shape)\n",
    "for i in range(0,int(testX_new.shape[0]/128)):\n",
    "    c=[]\n",
    "    for j in range(0,128):\n",
    "        c=c+list(testX_new.iloc[i*128+j,4:17])\n",
    "    testX_new1.loc[i]=c\n",
    "print(testX_new1.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       float64\n",
       "1       float64\n",
       "2       float64\n",
       "3       float64\n",
       "4       float64\n",
       "5       float64\n",
       "6       float64\n",
       "7       float64\n",
       "8       float64\n",
       "9       float64\n",
       "10      float64\n",
       "11      float64\n",
       "12      float64\n",
       "13      float64\n",
       "14      float64\n",
       "15      float64\n",
       "16      float64\n",
       "17      float64\n",
       "18      float64\n",
       "19      float64\n",
       "20      float64\n",
       "21      float64\n",
       "22      float64\n",
       "23      float64\n",
       "24      float64\n",
       "25      float64\n",
       "26      float64\n",
       "27      float64\n",
       "28      float64\n",
       "29      float64\n",
       "         ...   \n",
       "1122    float64\n",
       "1123    float64\n",
       "1124    float64\n",
       "1125    float64\n",
       "1126    float64\n",
       "1127    float64\n",
       "1128    float64\n",
       "1129    float64\n",
       "1130    float64\n",
       "1131    float64\n",
       "1132    float64\n",
       "1133    float64\n",
       "1134    float64\n",
       "1135    float64\n",
       "1136    float64\n",
       "1137    float64\n",
       "1138    float64\n",
       "1139    float64\n",
       "1140    float64\n",
       "1141    float64\n",
       "1142    float64\n",
       "1143    float64\n",
       "1144    float64\n",
       "1145    float64\n",
       "1146    float64\n",
       "1147    float64\n",
       "1148    float64\n",
       "1149    float64\n",
       "1150    float64\n",
       "1151    float64\n",
       "Length: 1152, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_new1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=500,criterion='entropy',random_state=222,max_depth=10,min_samples_leaf=4,min_samples_split=5)\n",
    "#print(cross_val_score(clf,trainX_new1,target,cv=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=222, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainX_new1,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(trainX_new1[3001:3810])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 4 0 8 0 1 4]\n",
      "[0 1 0 4 0 8 0 1 4 8]\n",
      "809\n"
     ]
    }
   ],
   "source": [
    "print(target[3001:3010])\n",
    "print(predictions[0:10])\n",
    "print(len(target[3001:3810] == predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(testX_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetx = trainY.iloc[:,2]\n",
    "cate=targetx.unique()\n",
    "predictions_new=cate[predictions]\n",
    "sub_df = pd.DataFrame({\"series_id\": list(range(3816))})\n",
    "sub_df[\"surface\"] = predictions_new\n",
    "sub_df[:10]\n",
    "sub_df.to_csv('rf_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 3 6 2]\n",
      "['hard_tiles_large_space' 'concrete' 'tiled' 'carpet' 'soft_tiles']\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:5])\n",
    "print(predictions_new[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_error: 0.451115\tvalid_1's multi_error: 0.479003\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_error: 0.451115\tvalid_1's multi_error: 0.479003\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.0031s\n",
      "fold n°1\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_error: 0.461942\tvalid_1's multi_error: 0.514436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_error: 0.461942\tvalid_1's multi_error: 0.514436\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.0061s\n",
      "fold n°2\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_error: 0.47605\tvalid_1's multi_error: 0.518373\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_error: 0.47605\tvalid_1's multi_error: 0.518373\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.0091s\n",
      "fold n°3\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_error: 0.464895\tvalid_1's multi_error: 0.545932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_error: 0.464895\tvalid_1's multi_error: 0.545932\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.012s\n",
      "fold n°4\n",
      "3048\n",
      "762\n",
      "1152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_error: 0.474738\tvalid_1's multi_error: 0.492126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\ttraining's multi_error: 0.474409\tvalid_1's multi_error: 0.493438\n",
      "(762, 1152)\n",
      "(3048, 1152)\n",
      "time elapsed: 0.015s\n",
      "CV score: 0.03071 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros((len(target),9))\n",
    "#categorical_columns = [c for c in categorical_columns if c not in ['MachineIdentifier']]\n",
    "#print(trainX_new1.iloc[1,])\n",
    "features = trainX_new1.columns\n",
    "predictions = np.zeros((len(testX_new1),9))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "start_time= time.time()\n",
    "score = [0 for _ in range(folds.n_splits)]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(trainX_new1.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print(len(trn_idx))\n",
    "    print(len(val_idx))\n",
    "    print(len(features))\n",
    "    trn_data = lgb.Dataset(trainX_new1.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           #categorical_feature = categorical_columns\n",
    "                          )\n",
    "    val_data = lgb.Dataset(trainX_new1.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           #categorical_feature = categorical_columns\n",
    "                          )\n",
    "\n",
    "    #print(trn_data.shape)\n",
    "    #print(val_data.shape)\n",
    "    num_round = 100\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "    print(trainX_new1.iloc[val_idx][features].shape)\n",
    "    print(trainX_new1.iloc[trn_idx][features].shape)\n",
    "    #tmp = clf.predict(trainX_new1.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    #print(tmp.shape)\n",
    "    oof[val_idx] = clf.predict(trainX_new1.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # we perform predictions by chunks\n",
    "    initial_idx = 0\n",
    "    chunk_size = 1000000\n",
    "    current_pred = np.zeros((len(testX_new1),9))\n",
    "    while initial_idx < testX_new1.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, testX_new1.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = clf.predict(testX_new1.iloc[idx][features], num_iteration=clf.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "    predictions += current_pred / min(folds.n_splits, max_iter)\n",
    "   \n",
    "    print(\"time elapsed: {:<5.2}s\".format((time.time() - start_time) / 3600))\n",
    "    #score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    tmp1=np.argmax(target.iloc[val_idx],axis=1)\n",
    "    tmp2=np.argmax(oof[val_idx],axis=1)\n",
    "    score[fold_] = metrics.accuracy_score(tmp1,tmp2)\n",
    "    if fold_ == max_iter - 1: break\n",
    "        \n",
    "if (folds.n_splits == max_iter):\n",
    "    #print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\n",
    "    tmp1=np.argmax(target,axis=1)\n",
    "    tmp2=np.argmax(oof,axis=1)\n",
    "    print(\"CV score: {:<8.5f}\".format(metrics.accuracy_score(tmp1,tmp2)))\n",
    "else:\n",
    "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028871391076115485, 0.02230971128608924, 0.03543307086614173, 0.030183727034120734, 0.03674540682414698]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.70141775e-02 6.32916360e-02 4.07728323e-02 6.13804365e-02\n",
      " 1.21029419e-01 6.43578701e-02 1.33642516e-01 1.27046866e-05\n",
      " 3.17130938e-01]\n",
      "8\n",
      "wood\n",
      "wood\n"
     ]
    }
   ],
   "source": [
    "targetx = trainY.iloc[:,2]\n",
    "cate=targetx.unique()\n",
    "predictions_new=np.argmax(predictions,axis=1)\n",
    "print(predictions[0,])\n",
    "print(predictions_new[0])\n",
    "print(cate[predictions_new[0]])\n",
    "predictions_new1=cate[predictions_new]\n",
    "print(predictions_new1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"series_id\": list(range(3816))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816\n",
      "(3816, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>soft_pvc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id   surface\n",
       "0          0      wood\n",
       "1          1  concrete\n",
       "2          2     tiled\n",
       "3          3      wood\n",
       "4          4     tiled\n",
       "5          5  concrete\n",
       "6          6  concrete\n",
       "7          7  concrete\n",
       "8          8  concrete\n",
       "9          9  soft_pvc"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions_new1))\n",
    "print(sub_df.shape)\n",
    "sub_df[\"surface\"] = predictions_new1\n",
    "sub_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('lgb_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
